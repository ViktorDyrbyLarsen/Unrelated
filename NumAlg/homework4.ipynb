{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c65b236",
   "metadata": {},
   "source": [
    "# Homework 4\n",
    "\n",
    "study number: s234857"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "59cc2277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c534807",
   "metadata": {},
   "source": [
    "## Multiple choice:\n",
    "A: 3\n",
    "\n",
    "B: 1\n",
    "\n",
    "C: 2\n",
    "\n",
    "D: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81559478",
   "metadata": {},
   "source": [
    "## 2) Newton's method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed69624",
   "metadata": {},
   "source": [
    "### 1.\n",
    "The given system and Jacomian matrix is written as a function taking X and returning the system evaluated in X (FX) and the  Jacobian matrix (dFX), both as NumPy arrays,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c4def9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def F(X):\n",
    "    FX = np.array([\n",
    "        -X[0]**2 - X[0] + 2*X[1] - 18,\n",
    "        (X[0] - 1)**2 + (X[1] - 6)**2 - 25\n",
    "    ])\n",
    "\n",
    "    dFX = np.array([\n",
    "        [-2*X[0] - 1, 2],\n",
    "        [2*X[0]- 2, 2*X[1] - 12] \n",
    "    ])\n",
    "\n",
    "    return FX, dFX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf5e88bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.25, 0.25]),\n",
       " array([[-4.,  2.],\n",
       "        [ 1., 10.]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F(np.array([1.5,11]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c43c49c",
   "metadata": {},
   "source": [
    "### 2.\n",
    "The gradients of $F$ doesn't seem to blow up anywhere. Suiting starting points are therefore simply chosen close to the roots.\n",
    "\n",
    "The graph suggests that the roots of the system (i.e the intersection between the individual expressions) are around $X = [-2,10]$ and $[1.5,11]$. These points are therefore chosen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd20a0d0",
   "metadata": {},
   "source": [
    "### 3.\n",
    "The Newtonsys function is from the exercises is imported and used for the exercise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "190d6644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Newtonsys(FdF, X0, kmax):\n",
    "    \"\"\"Solve system f(x) = 0 by Newton's method.\n",
    "\n",
    "F(x) and F'(x) are computed by the user-supplied function FdF with the\n",
    " call [F,dF] = FdF(x), where F is a np.array holding the computed vector F(x) and\n",
    " dF is a np.array holding the computed matrix F'(x).\n",
    "\n",
    "The starting point is x0.\n",
    " \n",
    "The function carries out kmax iterations, and stores all kmax iterations\n",
    "as columns on the output matrix Xiterations.\n",
    "\n",
    "Per Christian Hansen and Hans Bruun Nielsen, DTU Compute, April 11, 2016.\n",
    "\n",
    "Translated to Python spring 2023.\n",
    "\n",
    "    Args:\n",
    "        FdF (function): Function that computes F(x) and F'(x). Must return two np.arrays.\n",
    "        X0 (np.array): The starting point\n",
    "        kmax (int): Maximal number of iterations\n",
    "\n",
    "    Returns:\n",
    "        np.array: Iterations, stored columnwise\n",
    "    \"\"\"    \n",
    "\n",
    "    # Initialization\n",
    "    X = X0\n",
    "    Fx, dFx = FdF(X)\n",
    "    H = np.linalg.solve(dFx,Fx) # This is the first step.\n",
    "    \n",
    "    # Create the array to store the iterations.\n",
    "    \n",
    "    Xiterations = []\n",
    "    # Now iterate.\n",
    "    for k in range(1, kmax+1):\n",
    "        X = X - H\n",
    "        Xiterations.append(X)\n",
    "        Fx, dFx = FdF(X)\n",
    "        H = np.linalg.solve(dFx,Fx)\n",
    "    \n",
    "\n",
    "    return np.array(Xiterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3e0cbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.54694647 10.96999493]\n",
      "[-2. 10.]\n"
     ]
    }
   ],
   "source": [
    "X0s = [np.array([1.5,11]), np.array([-2,10])]\n",
    "kmax = 100\n",
    "for X0 in X0s:\n",
    "    Xit = Newtonsys(F, X0, kmax)\n",
    "    print((Xit[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe8e4f4",
   "metadata": {},
   "source": [
    "With 4 significant digits the found solution becomes\n",
    "\n",
    "\\begin{align*}\n",
    "r_1 &= [1.547, 10.97]\\\\r_2 &= [-2,10]\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f105a3ec",
   "metadata": {},
   "source": [
    "### 4.\n",
    "To examine convergence, we look at the series $$\\left\\{ \\frac{e_{k+1}}{e_{k}^2}\\right\\}_{k=0}^{6}.$$ If there is quadratic convergence, the series is expected to converge to some constant.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "03fb2f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.float64(0.057679595628006036), np.float64(0.11122976486773244), np.float64(0.1910709454299745), np.float64(0.255900032388262), np.float64(0.27143660144657744), np.float64(0.2720111842618869)]\n"
     ]
    }
   ],
   "source": [
    "X0 = np.array([0, 10])\n",
    "max_iter = 8\n",
    "\n",
    "X = Newtonsys(F, X0, max_iter)\n",
    "Xstar = X[-1]\n",
    "e = np.array([\n",
    "    np.linalg.norm(X[k] - Xstar) for k in range(7)\n",
    "])\n",
    "print(([e[k+1] / e[k]**2 for k in range(6)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6acc14",
   "metadata": {},
   "source": [
    "The series seems to approximately converge towards 0.27, i.e. indicating quadratic convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d0d9ce",
   "metadata": {},
   "source": [
    "## 3) Sensitivity analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a78bd02",
   "metadata": {},
   "source": [
    "### 1.\n",
    "Using that $\\delta |b_i| \\leq 0.005, \\forall i \\in \\{1, ..., 100 \\}$ and the triangle inequality,\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "\\|\\delta b\\|_2 &= \\left( \\sum_{k=1}^{100} |b_1|^2 \\right)^\\frac{1}{2}\n",
    "\\\\ &\\leq \\left( \\sum_{k=1}^{100} 0.005^2 \\right)^\\frac{1}{2}\n",
    "\\\\ &= 0.05.\n",
    "\\end{align*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eec0c5e",
   "metadata": {},
   "source": [
    "### 2.\n",
    "Using the inequality for relative error from week 11 - slide 22,, we have\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\|\\delta x\\|_2}{\\|x\\|_2} &\\leq \\kappa(A)\\frac{\\| \\delta b \\|_2}{\\|b \\|_2}\n",
    "\\\\&\\leq 2.2 \\frac{0.05}{1.4}\n",
    "\\\\&= 0.07857\n",
    "\\end{align*}\n",
    "\n",
    "giving the upper bound for $\\|\\delta x\\|_2$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
